---
title: "mini-project"
author: "Vina Nguyen"
date: "2023-05-08"
output:
  pdf_document: default
  html_document: default
---
```{r}
library(dplyr)
library(ggplot2)
library(stringr)
```


# Preparing the Data

First we download and import our data. Use read.csv() function to read the CSV files.
Assign the results to an object called wisc.df

Insert R Chunck Shortcut = ctrl+alt+i

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names = 1)
wisc.df
```

Set up new vector called diagnosis that contains the data from the diagnosis column of the original data. Store as factor for later.

```{r}
wisc.df$diagnosis

# use as.numeric() to read characters as numbers
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
```

Use -1 to remove the first column.

```{r}
wisc.data <- wisc.df[-1]
wisc.data
```

# Exploratory Data Analysis

> Q1. How many observations are in this dataset?

```{r}
nrow(wisc.df) # number of obs
dim(wisc.df) # number of obs and var
```

> Q2. How many of the observations have a malignant diagnosis?

```{r}
sum(diagnosis)
```

>Q3. How many variables/features in the data are suffixed with _mean?

```{r}
library(stringr)
cn <- colnames(wisc.df, do.NULL = TRUE, prefix = "col")
sum(str_count(cn, "_mean"))
```
# Principal Components Analysis
## Performing PCA

Check if data needs to be scaled before performing PCA.
Common reasons for scaling data:
- the input variables use different units of measurements
- the input variables have significantly different variances

```{r}
# check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

Excecute PCA with prcomp() function on wisc.data and assign the output model to wisc.pr.

```{r}
wisc.pr <- prcomp(wisc.data, scale = T, center = T)

# look at summary results
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

0.4371 (43%)

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

27 PCs

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

23 PCs

## Interpreting PCA Results

```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

Labels stands out. It is extremely hard to read because everything (labels and points) overlaps.

Generate a more standard scatter plot of each observation along principal components 1 and 2 and color points by diagnosis. 

```{r}
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x[, c(1, 2)], col = diagnosis + 1 , 
     xlab = "PC1", ylab = "PC2") +
  title("Observations by Components 1 and 2")
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots

```{r}
# Scatter plot observations by components 1 and 3
plot(wisc.pr$x[, c(1, 3)], col = diagnosis + 1 , 
     xlab = "PC1", ylab = "PC3") +
  title("Observations by Components 1 and 3")
```

The data points in first plot (PC1 vs PC2) have a more defined separation than the second plot (PC1 vs PC3). Principal component 2 explains more variance in the original data than principal component 3.

Create ggplot to make a fancier figure of these results.

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
g <- ggplot(df) + 
  aes(PC1, PC2, col= diagnosis) + 
  geom_point()
g
```

## Variance Explained

```{r}
# Calculate variance of each component
pr.var <- (wisc.pr$sdev)^2
head(pr.var)
```
```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

## Communicating PCA Results

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation[,1] 
```
0.26476411  

>Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
# use horizontal line = 0.8
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "b")
```

5

# Hierarchical Clustering

First scale the wisc.data data and assign the result to data.scaled.

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

Calculate the (Euclidean) distances between all pairs of observations in the new scaled data set and assign the result to data.dist.

```{r}
# Calculate the (Euclidean) distances: data.dist
data.dist <- dist(data.scaled)
```

Create a hierarchical clustering model using complete linkage. Manually specify the method argument to hclust() and assign the results to wisc.hclust.

```{r}
# Create a hierarchical clustering model: wisc.hclust
wisc.hclust <- hclust(data.dist, method = "complete")
```

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(h=20, col="red", lty=2)
```

Use cutree() to cut the tree so that it has 4 clusters. Assign the output to the variable wisc.hclust.clusters.

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=20)
```

We can use the table() function to compare the cluster membership to the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
wisc.hclust.clusters2 <- cutree(wisc.hclust, h=10)
table(wisc.hclust.clusters2, diagnosis)
```

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

```{r}
wisc.pr.hclust <- hclust(data.dist, method = "ward.D2")
plot(wisc.hclust)
abline(h=20, col="red", lty=2)
```

I like the first method better because the "single" method is harder to read and visually organize. "Ward.D2" is also nice because it is easy to read (less cluttered). Can see clusters better.

# Combining Methods

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```
```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

```{r}
g <- as.factor(grps)
levels(g)
```
```{r}
# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```

> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```

> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
# Create a k-means model on wisc.data: wisc.km
wisc.km<-kmeans(scale(wisc.data), centers = 2, nstart = 20)
# Compare k-means to actual diagnoses
table(wisc.km$cluster, diagnosis)
table(wisc.hclust.clusters, diagnosis)
```
```{r}

```

# Sensitivity/Specificity

- Sensitivity refers to a test’s ability to correctly detect ill patients who do have the condition. In our example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

- Specificity relates to a test’s ability to correctly reject healthy patients without a condition. In our example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC2") is better for sensitivity
     
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o") better for specificity

# Prediction 

Use predict() function for new data.

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

Prioritize on patient 1 because their results are malignant (red) unlike patient 2 with results that are benign (black).

# About this Document

```{r}
sessionInfo()
```















